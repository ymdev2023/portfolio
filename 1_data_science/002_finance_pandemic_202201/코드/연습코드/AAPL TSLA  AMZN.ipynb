{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb947408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:13.950341Z",
     "start_time": "2022-01-20T04:33:13.936185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Parameters \n",
    "n = 3 #the # of article headlines displayed per ticker\n",
    "tickers = ['AAPL', 'TSLA', 'AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce481f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:16.512412Z",
     "start_time": "2022-01-20T04:33:14.379631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recent News Headlines for AAPL: \n",
      "Dow Jones Futures: Market Correction Extends Losses; Four Stocks In Beat-Up Sector Worth Watching ( Jan-19-22 10:11PM )\n",
      "Sonos, Yelp Tell White House to Back Big Tech Antitrust Bill ( 09:24PM )\n",
      "U.S. Antitrust Bill Expanded to Include TikTok, Tencents WeChat ( 09:06PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for TSLA: \n",
      "Gilbert & Cook, Inc. Buys Vanguard FTSE Developed Markets ETF, Vanguard Total Bond Market ... ( Jan-19-22 05:38PM )\n",
      "Acas, Llc Buys Vanguard Extended Market Index ETF, Vanguard High Dividend Yield Indx ETF, ... ( 05:38PM )\n",
      "Syverson Strege & Co Buys BTC BlackRock Short Maturity Municipal Bond ETF, Dimensional ... ( 05:38PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for AMZN: \n",
      "Salvus Wealth Management, LLC Buys Verizon Communications Inc, Gartner Inc, Nike Inc, Sells ... ( Jan-19-22 09:38PM )\n",
      "Sonos, Yelp Tell White House to Back Big Tech Antitrust Bill ( 09:24PM )\n",
      "U.S. Antitrust Bill Expanded to Include TikTok, Tencents WeChat ( 09:06PM )\n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "    resp = urlopen(req)    \n",
    "    html = BeautifulSoup(resp, features=\"lxml\")\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "try:\n",
    "    for ticker in tickers:\n",
    "        df = news_tables[ticker]\n",
    "        df_tr = df.findAll('tr')\n",
    "    \n",
    "        print ('\\n')\n",
    "        print ('Recent News Headlines for {}: '.format(ticker))\n",
    "        \n",
    "        for i, table_row in enumerate(df_tr):\n",
    "            a_text = table_row.a.text\n",
    "            td_text = table_row.td.text\n",
    "            td_text = td_text.strip()\n",
    "            print(a_text,'(',td_text,')')\n",
    "            if i == n-1:\n",
    "                break\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7228602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:26.716020Z",
     "start_time": "2022-01-20T04:33:26.702964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ym\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2adeed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:29.526729Z",
     "start_time": "2022-01-20T04:33:29.496886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through the news\n",
    "parsed_news = []\n",
    "for file_name, news_table in news_tables.items():\n",
    "    for x in news_table.findAll('tr'):\n",
    "        text = x.a.get_text() \n",
    "        date_scrape = x.td.text.split()\n",
    "\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        parsed_news.append([ticker, date, time, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "115a1c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:31.650866Z",
     "start_time": "2022-01-20T04:33:31.580631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "news = pd.DataFrame(parsed_news, columns=columns)\n",
    "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "news = news.join(df_scores, rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aa634f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:32.656180Z",
     "start_time": "2022-01-20T04:33:32.628590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "AAPL    2022-01-19  10:11PM  0.158  0.643  0.199   -0.0772\n",
      "AAPL    2022-01-19  09:24PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  09:06PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  04:23PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  03:20PM  0.000  1.000  0.000    0.0000\n",
      "\n",
      "\n",
      "              Date     Time  neg  neu  pos  compound\n",
      "Ticker                                              \n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  04:24PM  0.0  1.0  0.0       0.0\n",
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "AMZN    2022-01-19  09:38PM  0.000  0.802  0.198    0.4939\n",
      "AMZN    2022-01-19  09:24PM  0.000  1.000  0.000    0.0000\n",
      "AMZN    2022-01-19  09:06PM  0.000  1.000  0.000    0.0000\n",
      "AMZN    2022-01-19  07:35PM  0.109  0.891  0.000   -0.0258\n",
      "AMZN    2022-01-19  07:08PM  0.000  0.884  0.116    0.1779\n",
      "\n",
      "\n",
      "        Mean Sentiment\n",
      "Ticker                \n",
      "AMZN              0.20\n",
      "AAPL              0.11\n",
      "TSLA              0.07\n"
     ]
    }
   ],
   "source": [
    "# View Data \n",
    "news['Date'] = pd.to_datetime(news.Date).dt.date\n",
    "\n",
    "unique_ticker = news['Ticker'].unique().tolist()\n",
    "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
    "\n",
    "values = []\n",
    "for ticker in tickers: \n",
    "    dataframe = news_dict[ticker]\n",
    "    dataframe = dataframe.set_index('Ticker')\n",
    "    dataframe = dataframe.drop(columns = ['Headline'])\n",
    "    print ('\\n')\n",
    "    print (dataframe.head())\n",
    "    \n",
    "    mean = round(dataframe['compound'].mean(), 2)\n",
    "    values.append(mean)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
    "df = df.set_index('Ticker')\n",
    "df = df.sort_values('Mean Sentiment', ascending=False)\n",
    "print ('\\n')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0379698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T04:33:36.779973Z",
     "start_time": "2022-01-20T04:33:33.237471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recent News Headlines for AAPL: \n",
      "Dow Jones Futures: Market Correction Extends Losses; Four Stocks In Beat-Up Sector Worth Watching ( Jan-19-22 10:11PM )\n",
      "Sonos, Yelp Tell White House to Back Big Tech Antitrust Bill ( 09:24PM )\n",
      "U.S. Antitrust Bill Expanded to Include TikTok, Tencents WeChat ( 09:06PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for TSLA: \n",
      "Gilbert & Cook, Inc. Buys Vanguard FTSE Developed Markets ETF, Vanguard Total Bond Market ... ( Jan-19-22 05:38PM )\n",
      "Acas, Llc Buys Vanguard Extended Market Index ETF, Vanguard High Dividend Yield Indx ETF, ... ( 05:38PM )\n",
      "Syverson Strege & Co Buys BTC BlackRock Short Maturity Municipal Bond ETF, Dimensional ... ( 05:38PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for AMZN: \n",
      "Salvus Wealth Management, LLC Buys Verizon Communications Inc, Gartner Inc, Nike Inc, Sells ... ( Jan-19-22 09:38PM )\n",
      "Sonos, Yelp Tell White House to Back Big Tech Antitrust Bill ( 09:24PM )\n",
      "U.S. Antitrust Bill Expanded to Include TikTok, Tencents WeChat ( 09:06PM )\n",
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "AAPL    2022-01-19  10:11PM  0.158  0.643  0.199   -0.0772\n",
      "AAPL    2022-01-19  09:24PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  09:06PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  04:23PM  0.000  1.000  0.000    0.0000\n",
      "AAPL    2022-01-19  03:20PM  0.000  1.000  0.000    0.0000\n",
      "\n",
      "\n",
      "              Date     Time  neg  neu  pos  compound\n",
      "Ticker                                              \n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  05:38PM  0.0  1.0  0.0       0.0\n",
      "TSLA    2022-01-19  04:24PM  0.0  1.0  0.0       0.0\n",
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "AMZN    2022-01-19  09:38PM  0.000  0.802  0.198    0.4939\n",
      "AMZN    2022-01-19  09:24PM  0.000  1.000  0.000    0.0000\n",
      "AMZN    2022-01-19  09:06PM  0.000  1.000  0.000    0.0000\n",
      "AMZN    2022-01-19  07:35PM  0.109  0.891  0.000   -0.0258\n",
      "AMZN    2022-01-19  07:08PM  0.000  0.884  0.116    0.1779\n",
      "\n",
      "\n",
      "        Mean Sentiment\n",
      "Ticker                \n",
      "AMZN              0.20\n",
      "AAPL              0.11\n",
      "TSLA              0.07\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen, Request\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Parameters \n",
    "n = 3 #the # of article headlines displayed per ticker\n",
    "tickers = ['AAPL', 'TSLA', 'AMZN']\n",
    "\n",
    "# Get Data\n",
    "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finwiz_url + ticker\n",
    "    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "    resp = urlopen(req)    \n",
    "    html = BeautifulSoup(resp, features=\"lxml\")\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "try:\n",
    "    for ticker in tickers:\n",
    "        df = news_tables[ticker]\n",
    "        df_tr = df.findAll('tr')\n",
    "    \n",
    "        print ('\\n')\n",
    "        print ('Recent News Headlines for {}: '.format(ticker))\n",
    "        \n",
    "        for i, table_row in enumerate(df_tr):\n",
    "            a_text = table_row.a.text\n",
    "            td_text = table_row.td.text\n",
    "            td_text = td_text.strip()\n",
    "            print(a_text,'(',td_text,')')\n",
    "            if i == n-1:\n",
    "                break\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Iterate through the news\n",
    "parsed_news = []\n",
    "for file_name, news_table in news_tables.items():\n",
    "    for x in news_table.findAll('tr'):\n",
    "        text = x.a.get_text() \n",
    "        date_scrape = x.td.text.split()\n",
    "\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        parsed_news.append([ticker, date, time, text])\n",
    "        \n",
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "news = pd.DataFrame(parsed_news, columns=columns)\n",
    "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "news = news.join(df_scores, rsuffix='_right')\n",
    "\n",
    "\n",
    "# View Data \n",
    "news['Date'] = pd.to_datetime(news.Date).dt.date\n",
    "\n",
    "unique_ticker = news['Ticker'].unique().tolist()\n",
    "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
    "\n",
    "values = []\n",
    "for ticker in tickers: \n",
    "    dataframe = news_dict[ticker]\n",
    "    dataframe = dataframe.set_index('Ticker')\n",
    "    dataframe = dataframe.drop(columns = ['Headline'])\n",
    "    print ('\\n')\n",
    "    print (dataframe.head())\n",
    "    \n",
    "    mean = round(dataframe['compound'].mean(), 2)\n",
    "    values.append(mean)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
    "df = df.set_index('Ticker')\n",
    "df = df.sort_values('Mean Sentiment', ascending=False)\n",
    "print ('\\n')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77fab76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1852ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
